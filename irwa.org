* Introduction to Rust Web Applications

  All glory to [[https://erwabook.com/intro/index.html][Introduction to Rust Web Applications]]

  This goes over a full stack, all Rust approach to building web apps.

  It builds a todo app (as tradition), and walks through the layers of the app starting from the database.
  
  It uses SQLite3 as the db engine
  
  Then we write a db access library that higher layers will build on. We will
  be using CLI driven programs that use the db access layer to read and write to the database. This is generally more
  convenient and safer than modifying or querying the db directly.

  Then we have the REST API (built on Rocket)

  Our frontend client will send HTTP requests to our Rocket program. When Rocket calls our code, we will use the db access layer to read or write to the DB.
  The REST API code will massage the data into an appropriate format (JSON) before returning it to the client.

  The top layer, or frontend, is the web ui that is presented to the user. This runs in a web browser as WebAssembly (JavaScript). We will use the Seed framework
  to compile our Rust code into a webassembly app that we can load into the browser.

* Set up ORM & Database

  We assume sqlite is installed.
  
** Install Diesel

   Diesel is an ORM for Rust that provides us with a type-safe way to interact with the database.

#+BEGIN_SRC toml 
[package]
name = "irwa"
version = "0.1.0"
authors = ["dr-neptune <mrose4@worcester.edu>"]
edition = "2018"

# See more keys and their definitions at https://doc.rust-lang.org/cargo/reference/manifest.html

[dependencies]
diesel = { version = "1.0.0", features = ["sqlite"]}
#+END_SRC

We can also install the Diesel cli

#+BEGIN_SRC bash
cargo install diesel_cli --no-default-features --features sqlite
#+END_SRC

This installs the Diesel CLI tool will support for SQLite3

We need to tell the diesel_cli what our database filename is.

**Note:**

In order to get diesel_cli to work with nix, I needed to include sqlite as a service in my nix-shell file

#+name:
#+BEGIN_SRC nix
let
  moz_overlay = import (builtins.fetchTarball https://github.com/mozilla/nixpkgs-mozilla/archive/master.tar.gz);
  nixpkgs = import <nixpkgs> {
    overlays = [ moz_overlay ];
  };
  ruststable = (nixpkgs.latest.rustChannels.stable.rust.override {
    extensions = [ "rust-src"
                   "clippy-preview"
                   "rls-preview"
                   "rustfmt-preview"
                   # "llvm-tools"
                   "rust-analysis"
                   "rust-std"
                   "rustc-dev"];}
  );
in
with nixpkgs;
stdenv.mkDerivation {
  name = "rust";
  buildInputs = [ rustup ruststable glibc sqlite ];
}
#+END_SRC

Next we want to tell diesel_cli what our database filename is.

We can do this by using the DATABASE_URL environment variable, or by setting a file called .env.

#+name:
#+BEGIN_SRC bash
echo 'DATABASE_URL=./testdb.sqlite3' > .env
# get diesel to setup our workspace for us
diesel setup
#+END_SRC

Now we should have a database, and we should see a file called testdb.sqlite3 in our directory contents.

* Write the First Migration

  Now that we have a database and ORM installed, we should store some structured data.
  
  Diesel makes changes to the database structure as a series of "migrations". For each migration, we need to provide the SQL commands required both to implement whatever db change we're making and to undo that change.
  So whenever we write a migration that creates a new table, we also need to provide the SQL to remove that table if our migration needs to be undone.

** Generate the Skeleton

   We'll use diesel's cli to generate our first migration:

#+name:
#+BEGIN_SRC bash
diesel migration generate task
#+END_SRC

In our new migrations folder, we have another timestamped subdirectory with two stub files, up and down.sql

** Write the SQL

#+name:
#+BEGIN_SRC sql 
CREATE TABLE task (
id INTEGER NOT NULL,
title TEXT NOT NULL,
PRIMARY KEY (id)
);
#+END_SRC

This will create a very simple table for storing our task list.

** Test the Migration

#+name:
#+BEGIN_SRC bash
diesel migration run
echo .dump | sqlite3 testdb.sqlite3
#+END_SRC

The last command will show the table we created.

The other part of testing a migration is ensuring that rollbacks work. This is done via the redo command, which revents to the latest migration and then re-runs it.

#+name:
#+BEGIN_SRC bash
diesel migration redo
#+END_SRC

Our redo failed because we forgot to modify down.sql

#+name:
#+BEGIN_SRC sql :tangle irwa/migrations/2021-02-14-004828_task/down.sql 
DROP TABLE task;
#+END_SRC

Now it runs successfully

* Create a Database Access Layer

  For the convenience of our upper layer application, we'll write a set of thin wrappers around the Diesel code and expose it as a module.

  As one way of testing these wrappers, we'll also build an executable with subcommands that exercise each of the wrapper functions.
  Then this suite of subcommands can be used as a debugging / troubleshooting / experimentation tool.

** Inserting a Task

   We currently just have one table, with no rows.

   We now also have a diesel.toml in our directory

#+name:
#+BEGIN_SRC bash :dir irwa
ls
#+END_SRC

| Cargo.lock     |
| Cargo.toml     |
| diesel.toml    |
| migrations     |
| src            |
| target         |
| testdb.sqlite3 |

#+name:
#+BEGIN_SRC toml
[print_schema]
file = "src/schema.rs"
#+END_SRC

This refers to a src/schema.rs

#+name:
#+BEGIN_SRC rust
table! {
    task (id) {
        id -> Integer,
        title -> Text,
    }
}
#+END_SRC

We got this when we ran our schema migration. It will automatically get updated every time we run a migration (in either direction). The table! macro generates a bunch of code that we can use to work with the tables in our database.

First we need to think about where we want to keep this code. Right now all we have is a binary crate, but we want to build up a little library.

Lets plan on having the following structure

mytodo
  +-- db
  |    +-- models
  |    +-- schema
  +-- rest

  We'll create the db module now. We have to let Rust know we're making a db module by creating a src/lib.rs

#+name:
#+BEGIN_SRC rust :tangle irwa/backend/src/lib.rs
#[macro_use]
extern crate diesel;

// needed for json serialization at the rest api level
#[macro_use]
extern crate serde;

pub mod db;
#+END_SRC

That also pulls in Diesel's macros -- our code will heavily rely on those.

Now we want to update our diesel.toml to point to the new location:

#+name:
#+BEGIN_SRC toml :tangle irwa/diesel.toml
[print_schema]
file = "backend/src/db/schema.rs"
#+END_SRC

We can test that we've got Diesel set up correctly by removing the existing schema.rs file and rerunning the migration to generate a new one

#+name:
#+BEGIN_SRC bash 
rm src/schema.rs
diesel migration redo
ls src/db
#+END_SRC

Now we can make some glue. We need to define some types that we can use for reading and writing to the database.

#+name:
#+BEGIN_SRC rust
use super::schema::task;

#[derive(Insertable)]
#[table_name = "task"]
pub struct NewTask<'a> {
    pub title: &'a str,
}
#+END_SRC

By deriving our struct from Insertable and setting the table_name to what we've got in our schema, Diesel will automagically give us code to perform database inserts.
In src/db/mod.rs we can add our function to take advantage of this:

#+name:
#+BEGIN_SRC rust
use diesel::{prelude::*, sqlite::SqliteConnection};

// expose our models and schema submodules
pub mod models;
pub mod schema;

// connect to the database
pub fn establish_connection() -> SqliteConnection {
    // anything not a toy application needs a better mechanism for setting the path to the database
    let db = "./testdb.sqlite3";
    SqliteConnection::establish(db)
	.unwrap_or_else(|_| panic!("Error connecting to {}", db))
}

// create a task
pub fn create_task(connection: &SqliteConnection, title: &str) {
    // create an object from a struct we defined in models
    let task = models::NewTask { title, status: "pending" };

    // takes the table from our schema, gives us back an object that we can add to with values
    diesel::insert_into(schema::task::table)
	.values(&task)
	// which we can execute
	.execute(connection)
	.expect("Error inserting new task");
}
#+END_SRC

** Create a Development Tool

   Now we can create the tool mentioned earlier to read and write from the database.

   First we create the infrastructure for that

#+BEGIN_SRC bash
mkdir src/bin
#+END_SRC

#+name:
#+BEGIN_SRC rust
// for processing command line arguments
use std::env;
// for using the db functions we just wrote
use irwa::db::{create_task, establish_connection, query_task};

// print help in the event of unparseable sets of arguments
fn help() {
    println!("subcommands:");
    println!("    new<title>: create a new task");
    println!("    show: show current tasks");
}

// subcommand handler for new task
fn new_task(args: &[String]) {
    if args.len() < 1 {
	println!("new: missing <title>");
	help();
	return;
    }

    // ow we good
    let conn = establish_connection();
    create_task(&conn, &args[0]);
}

// match the first arg against our set of possible subcommands and dispatch the remaining args to a handler. Call help in case there is no arg or we can't parse it
fn main() {
    let args: Vec<String> = env::args().collect();

    if args.len() < 2 {
	help();
	return;
    }

    let subcommand = &args[1];
    match subcommand.as_ref() {
	"new" => new_task(&args[2..]),
	"show" => show_tasks(&args[2..]),
	_ => help(),
    }
}
#+END_SRC

Now we can test it

#+name:
#+BEGIN_SRC bash
cargo run --bin todo new 'do the thing'
cargo run --bin todo new 'get stuff done'
echo 'select * from task;' | sqlite3 testdb.sqlite3
#+END_SRC

** Querying Tasks

   When we wrote our insertion function, we used a struct that was derived from Insertable. To perform queries, we'll want to use a struct derived from Queryable.

   We will add this to src/db/models.rs

#+BEGIN_SRC rust :tangle irwa/backend/src/db/models.rs
#[derive(Queryable, Identifiable, Serialize)]
#[table_name = "task"]
pub struct Task {
    pub id: i32,
    pub title: String,
    pub status: String,
}
#+END_SRC

#+name:
#+BEGIN_SRC rust :tangle irwa/backend/src/db/mod.rs
// return a Vec of this new model struct when querying the task table
pub fn query_task(connection: &SqliteConnection) -> Vec<models::Task> {
    schema::task::table
	.load::<models::Task>(connection)
	.expect("Error loading tasks")
}
#+END_SRC

And we should add a new subcommand handler to src/bin/todo.rs

#+name:
#+BEGIN_SRC rust
fn show_tasks(args: &[String]) {
    if args.len() > 0 {
	println!("show: unexpected argument");
	help();
	return;
    }

    let conn = establish_connection();

    println!("Tasks\n-----");
    for task in query_task(&conn) {
	println!("{}", task.title);
    }
}
#+END_SRC

We've written a very simple data abstraction layer, and we've exercised it by writing a CLI tool for poking and peeking at the database.

Our data model is so simple, our app isn't actually capable of being useful. There is no mechanism to mark a task done, or even delete a task.

We are completely missing
- comments
- documentation outside of help
- tests
- continuous integration

Even with these shortcomings we have enough infrastructure upon which to build out next layer, the REST API.

** Database Layer Exercises

*** Add a "done" column to the table

Write and run a migration, update the models, update the insertion code to set the task as pending (not done) on creation, and update the show subcommand to show done/pending status.

So for this we need to:
update the up sql command to contain another column for task status
set the default as pending
update the show command to show done / pending status

#+name:
#+BEGIN_SRC sql :tangle irwa/migrations/2021-02-14-004828_task/up.sql 
CREATE TABLE task (
id INTEGER NOT NULL,
title TEXT NOT NULL,
status TEXT NOT NULL,
PRIMARY KEY (id)
);
#+END_SRC

#+name:
#+BEGIN_SRC rust :tangle irwa/backend/src/db/models.rs
use super::schema::task;

#[derive(Insertable, AsChangeset)]
#[table_name = "task"]
pub struct NewTask<'a> {
    pub title: &'a str,
    pub status: &'a str,
}
#+END_SRC

#+name:
#+BEGIN_SRC rust :tangle irwa/backend/src/db/mod.rs
use diesel::{prelude::*, sqlite::SqliteConnection};
// use schema::tasks::dsl::task::status, status};
use crate::db::schema::task::status;

// expose our models and schema submodules
pub mod models;
pub mod schema;

// connect to the database 
pub fn establish_connection() -> SqliteConnection {
    // anything not a toy application needs a better mechanism for setting the path to the database
    let db = "./testdb.sqlite3";
    SqliteConnection::establish(db)
	.unwrap_or_else(|_| panic!("Error connecting to {}", db))
}

// create a task
pub fn create_task(connection: &SqliteConnection, title: &str) {
    // create an object from a struct we defined in models
    let task = models::NewTask { title: title, status: "pending" };

    // takes the table from our schema, gives us back an object that we can add to with values
    diesel::insert_into(schema::task::table)
	.values(&task)
	// which we can execute
	.execute(connection)
	.expect("Error inserting new task");

    println!("Adding Task: {}", title);
}

pub fn update_status(title: &[String], new_status: String) {
    let id = lookup_title_id(title);
    let conn = establish_connection();
    for task in query_task(&conn) {
	if &id == &task.id {
	    // update it!
	    diesel::update(&task)
		.set(status.eq(&new_status))
		.execute(&conn)
		.expect("Error updating task");
	    println!("Updated Task: {} to [{}]", &title[0], new_status);
	}
    }
}

pub fn delete_task(title: &[String]) {
    let id = lookup_title_id(title);
    let conn = establish_connection();
    for task in query_task(&conn) {
	if &id == &task.id {
	    diesel::delete(&task)
		.execute(&conn)
		.expect("Error deleting task");
	    println!("Deleted Task: {}", &title[0]);
	}
    }
}

fn lookup_title_id(arg: &[String]) -> i32 {
    let conn = establish_connection();

    for task in query_task(&conn) {
	if &arg[0] == &task.title {
	    return task.id;
	}
    }
    return 0;
}
#+END_SRC

#+BEGIN_SRC rust :tangle irwa/backend/src/bin/todo.rs
fn show_tasks(args: &[String]) {
    if args.len() > 0 {
	println!("show: unexpected argument");
	help();
	return;
    }

    let conn = establish_connection();

    println!("Tasks\n-----");
    for task in query_task(&conn) {
	println!("Title:\t{}\nStatus:\t{}", task.title, task.status);
    }
}
#+END_SRC

Add a subcommand to mark tasks done. You'll need to decide whether to let the user provide the title or the id.
If the former, then in the db layer, you may need to add a function to look up by title, and call that from the subcommand so that you can pass the id to the other new db layer function you'll add that udpates the record to set done to true.
If the latter, you should probably modify the show subcommand to display ids.
This sounds like a lot of steps but they're all fairly simple. Check out the Diesel guides for help with queries that filter, and with update operations.

#+name:
#+BEGIN_SRC rust :tangle irwa/backend/src/bin/todo.rs
// we want it to return an id.
// if id not found, return 0
fn lookup_title_id(arg: &[String]) -> i32 {
    let conn = establish_connection();

    for task in query_task(&conn) {
	if &arg[0] == &task.title {
	    return task.id;
	}
    }
    return 0;
}

// write a fn that pattern matches on lookup_title_id output and outputs to the console
fn lookup_title(arg: &[String]) {
    if arg.len() == 0 {
	println!("lookup_title: no argument!");
	help();
	return;
    }
    if arg.len() > 1 {
	println!("lookup_title: only supports 1 title lookup at a time");
	help();
	return;
    }

    let val = lookup_title_id(arg);

    if val == 0 {
	println!("ID not found!");
    } else {
	println!("ID:\t{}", lookup_title_id(arg));
    }
}
#+END_SRC

Then we can update the todo to allow for calling the lookup

#+name:
#+BEGIN_SRC rust :tangle irwa/backend/src/bin/todo.rs
// for processing command line arguments
use std::env;
// for using the db functions we just wrote
use backend::db::{create_task, establish_connection, query_task, update_status, delete_task};

// print help in the event of unparseable sets of arguments
fn help() {
    println!("subcommands:");
    println!("    new <title>: create a new task");
    println!("    delete <title>: delete a task");
    println!("    show: show current tasks");
    println!("    lookup_title <title>: lookup id by title");
    println!("    pending <title>: set task to pending by title");
    println!("    done <title>: set task to done by title");
}

// subcommand handler for new task
fn new_task(args: &[String]) {
    if args.len() < 1 {
	println!("new: missing <title>");
	help();
	return;
    }

    // ow we good
    let conn = establish_connection();
    create_task(&conn, &args[0]);
}

// match the first arg against our set of possible subcommands and dispatch the remaining args to a handler. Call help in case there is no arg or we can't parse it
fn main() {
    let args: Vec<String> = env::args().collect();

    if args.len() < 2 {
	help();
	return;
    }

    let subcommand = &args[1];
    match subcommand.as_ref() {
	"new" => new_task(&args[2..]),
	"delete" => delete_task(&args[2..]),
	"show" => show_tasks(&args[2..]),
	"lookup_title" => lookup_title(&args[2..]),
	"pending" => update_status(&args[2..], "PENDING".to_string()),
	"done" => update_status(&args[2..], "DONE".to_string()),
	_ => help(),
    }
}
#+END_SRC


*** Add a subcommand to delete a task
As above, you'll need to decide whether to have the user provide the id or the title. Then add a db layer function to delete a task, and a subcommand to call it.

This was done.

* Create a REST API Layer

  Since our GUI is going to run in the browser, we need something for the browser to talk to.

** Add Rocket to Cargo.toml

#+name:
#+BEGIN_SRC toml
[package]
name = "irwa"
version = "0.1.0"
authors = ["dr-neptune <mrose4@worcester.edu>"]
edition = "2018"

# See more keys and their definitions at https://doc.rust-lang.org/cargo/reference/manifest.html

[dependencies]
diesel = { version = "1.0.0", features = ["sqlite"]}
rocket = "0.4.2"
#+END_SRC

** Create the Backend Binary

   We'll write our backend in src/bin/backend.rs

#+name:
#+BEGIN_SRC rust 
// macros that Rocket needs
#![feature(proc_macro_hygiene, decl_macro)]
#[macro_use]
extern crate rocket;

use irwa::db::models::Task;
use irwa::db::{query_task, establish_connection};

#[get("/tasks")]
fn tasks_get() -> String {
    "this is a response\n".into()
}

fn main() {
    rocket::ignite()
	.mount("/", routes![tasks_get])
	.launch();
}
#+END_SRC

** Querying the Database

   Now we want to update our code to actually get info from the database.
   
#+name:
#+BEGIN_SRC rust
// macros that Rocket needs
#![feature(proc_macro_hygiene, decl_macro)]
#[macro_use]
extern crate rocket;

use irwa::db::models::Task;
use irwa::db::{query_task, establish_connection};

#[get("/tasks")]
fn tasks_get() -> String {
    // "this is a response\n".into()
    let mut response: Vec<String> = vec![];

    let conn = establish_connection();
    for task in query_task(&conn) {
	response.push(task.title);
    }

    response.join("\n")
}

fn main() {
    rocket::ignite()
	.mount("/", routes![tasks_get])
	.launch();
}
#+END_SRC

We now see all the tasks shown on the screen!

Just printing a bunch of lines of output is good for now, but we will want to add more information and printing them all to output will become tedious over time.

We can make it easier for our frontend and our backend to communicate with each other if we use a standard data serialization format for our API.

** Serializing to JSON

   We need to add serde and JSON support from rocket_contrib to our Cargo.toml
   
#+name:
#+BEGIN_SRC toml
[package]
name = "irwa"
version = "0.1.0"
authors = ["dr-neptune <mrose4@worcester.edu>"]
edition = "2018"

# See more keys and their definitions at https://doc.rust-lang.org/cargo/reference/manifest.html

[dependencies]
# database ORM 
diesel = { version = "1.0.0", features = ["sqlite"]}
# backend
rocket = "0.4.2"
# framework for serializing and deserializing data
serde = { version = "1.0", features = ["derive"] }

[dependencies.rocket_contrib]
version = "0.4.2"
default-features = false
features = ["json"]
#+END_SRC

and then we need to use rocket_contrib and serde in backend.rs

#+name:
#+BEGIN_SRC rust
// macros that Rocket needs
#![feature(proc_macro_hygiene, decl_macro)]
#[macro_use]
extern crate rocket;
#[macro_use]
extern crate serde;


use irwa::db::models::Task;
use irwa::db::{query_task, establish_connection};

#[get("/tasks")]
fn tasks_get() -> String {
    // "this is a response\n".into()
    let mut response: Vec<String> = vec![];

    let conn = establish_connection();
    for task in query_task(&conn) {
	response.push(task.title);
    }

    response.join("\n")
}

fn main() {
    rocket::ignite()
	.mount("/", routes![tasks_get])
	.launch();
}
#+END_SRC

We will follow closely to the JSON API spec, which requires an object at the top level, and a data key at that level -- something like this:

#+name:
#+BEGIN_SRC json
{
    "data": [
	{ "id": 1, "title": "do the thing" },
	{ "id": 2, "title": "get stuff done" },
    ]
}
#+END_SRC

Note this isn't strictly conforming with the JSON API spec because the resource objects (the stuff in the data array) aren't formatted properly

Now we can put together a Rust structure to represent it in backend.rs:

#+BEGIN_SRC rust :tangle irwa/backend/src/bin/backend.rs
// macros that Rocket needs
#![feature(proc_macro_hygiene, decl_macro)]
#[macro_use]
extern crate rocket;
#[macro_use]
extern crate serde;

use backend::db::models::Task;
use backend::db::{query_task, establish_connection};
use rocket_contrib::json::Json;
use irwa::JsonApiResponse;

// magically returns JSON
// #[derive(Serialize)]
// struct JsonApiResponse {
//     data: Vec<Task>,
// }

#[get("/tasks")]
fn tasks_get() -> Json<JsonApiResponse> {
    // "this is a response\n".into()
    let mut response = JsonApiResponse { data: vec![], };

    let conn = establish_connection();
    for db_task in query_task(&conn) {
	let api_task = irwa::Task {
	    id: db_task.id,
	    title: db_task.title,
	};
	
	response.data.push(api_task);
    }

    Json(response)
}

fn main() {
    rocket::ignite()
	.mount("/", routes![tasks_get])
	.launch();
}
#+END_SRC

* Create a Browser-Based Frontend UI

  The last piece of our application is the UI, which will be based on the seed framework.

** Cargo Workspace

   This build works by generating a library, and Cargo only allows one library per crate. We already have one, so this seems like a problem -- but cargo supports workspaces where we can build multiple crates.

   We will build our backend (db + rest api) into one library crate and our frontend into a separate crate.

   Any shared structs that we define will be in the root crate.

   First we create a new crate as a subdirectory under our existing project directory:
   
#+name:
#+BEGIN_SRC bash
cargo new --lib frontend
#+END_SRC

Then we need to move our existing code into a new crate:

#+name:
#+BEGIN_SRC bash
cargo new --lib backend
mv src/lib.rs src/db src/bin/ backend/src
#+END_SRC

and fix up crate references in backend/src/bin/backend.rs and backend/src/bin/todo.rs

We can build the backend and frontend by adding them as workspace members:

#+name:
#+BEGIN_SRC toml :tangle irwa/Cargo.toml
[package]
name = "irwa"
version = "0.1.0"
authors = ["dr-neptune <mrose4@worcester.edu>"]
edition = "2018"

# See more keys and their definitions at https://doc.rust-lang.org/cargo/reference/manifest.html

# added during the frontend portion
[dependencies]
serde = { version = "1.0", features = ["derive"] }

[workspace]
members = ["backend", "frontend"]
#+END_SRC

#+name:
#+BEGIN_SRC toml :tangle irwa/backend/Cargo.toml
[package]
name = "backend"
version = "0.1.0"
authors = ["dr-neptune <mrose4@worcester.edu>"]
edition = "2018"

# See more keys and their definitions at https://doc.rust-lang.org/cargo/reference/manifest.html

[dependencies]
# database ORM 
diesel = { version = "1.0.0", features = ["sqlite"] }
# backend
rocket = "0.4.2"
# framework for serializing and deserializing data
serde = { version = "1.0", features = ["derive"] }
# added during frontend
irwa = { path = ".." }

[dependencies.rocket_contrib]
version = "0.4.2"
default-features = false
features = ["json"]
#+END_SRC

** Install wasm toolchain

   We are going to be cross compiling our code to wasm32. In order to do that, we need to install the toolchain.

   We also need to set up our crate to build wasm32 and add mytodo, seed, wasm-bindgen, and web-sys as dependencies.

#+name:
#+BEGIN_SRC toml :tangle irwa/frontend/Cargo.toml
[package]
name = "frontend"
version = "0.1.0"
authors = ["dr-neptune <mrose4@worcester.edu>"]
edition = "2018"

# See more keys and their definitions at https://doc.rust-lang.org/cargo/reference/manifest.html

[lib]
crate-type = ["cdylib"]

[dependencies]
irwa = { path = ".." }
futures = "^0.1.28"
seed = "^0.4.0"
wasm-bindgen = "^0.2.50"
web-sys = "^0.3.27"
#+END_SRC

We also had to add openssl pkg-config to our environment in the nix-shell and run

#+name:
#+BEGIN_SRC bash
cargo install wasm-pack
cd frontend
wasm-pack build --target web --out-name package --dev
#+END_SRC

This will leave output in frontend/dev/

** cargo make

cargo make is a tool we can use to automate our build tasks. This is similar to a makefile, but much more verbose. 

we install it with

#+name:
#+BEGIN_SRC bash
cargo install cargo-make
#+END_SRC

and to configure it, we create a new Makefile.toml in the root of our project directory:

#+name:
#+BEGIN_SRC toml :tangle irwa/Makefile.toml
[env]
CARGO_MAKE_EXTENDED_WORKSPACE_MAKEFILE = "true"

[tasks.default]
clear = true
dependencies = ["build"]
#+END_SRC

This file just defines one task: The default task is what gets run when you say cargo make.

cargo make knows about workspaces, and will run each task in each workspace.
The env variable in our Makefile will have cargo make look in workspace directories for Makefile.toml files, and any tasks in those files will override the tasks in the workspace-level Makefile.toml

#+name:
#+BEGIN_SRC toml :tangle irwa/frontend/Makefile.toml
[tasks.default]
dependencies = ["create_wasm"]

[tasks.create_wasm]
command = "wasm-pack"
args = ["build", "--target", "web", "--out-name", "package", "--dev"]
dependencies = ["build"]
#+END_SRC

With all that in place, running cargo make in the root will give us:
- backend library and binaries under target/debug
- browser loadable web assembly package in frontend/pkg/package_bg.wasm

** Behind the Scenes

   The way our frontend app is going to work:

   - we write some Rust
   - wasm-pack generates some files
     - the .wasm file is a WebAssembly binary
     - the .js file is a JavaScript loader that will pull in the wasm, and it acts as the gatekeeper between js and rust
     - package.json has some metadata in case we want to integrate with npm and friends
   - we write an html stub file that loads the .js file, which loads the .wasm
   - our app attaches itself to a DOM element in the html file
   - the browser shows our app's UI elements
   - our users rejoice

** Create the Stub App

#+name:
#+BEGIN_SRC html :tangle irwa/frontend/index.html
<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <title>DoItToDoIt</title>
  </head>
  <body>
    <div id="app"></div>
    <script type="module">
      <!-- we don't want to use a bundler like webpack -->
      <!-- in a real app we may want other web assets to be packed together with our app -->
      import init from '/pkg/package.js';
      init('/pkg/package_bg.wasm');
    </script>
  </body>
</html>
#+END_SRC 

All our html needs to do is provide a div with an id of app and the script snippet that loads the package.

#+name:
#+BEGIN_SRC rust :tangle irwa/frontend/src/lib.rs
#[macro_use]
extern crate seed;
use seed::prelude::*;
// for fetching data
use seed::{fetch, Request};
// for futures
use futures::Future;

fn fetch_drills() -> impl Future<Item = Msg, Error = Msg> {
    // create a future using the Requests struct 
    Request::new("http://localhost:8000/tasks")
	.fetch_json_data(Msg::FetchedTasks)
}

#[derive(Clone, Debug)]
enum Direction {
    Coming,
    Going,
}

struct Model {
    direction: Direction,
}

#[derive(Clone, Debug)]
enum Msg {
    FetchedTasks(fetch::ResponseDataResult<JsonApiResponse>),
}

fn update(msg: Msg, model: &mut Model, _orders: &mut impl Orders<Msg>) {
    match msg {
	Msg::FetchedTasks(Ok(result)) => {
	    // TODO: update the model
	}
	Msg::FetchedTasks(Err(reason)) => {
	    log!(format!("Error fetching: {:?}", reason));
	    orders.skip();
	}
    }
}

fn view(model: &Model) -> impl View<Msg> {
    let greeting = match model.direction {
	Direction::Coming => "Hello, World!",
	Direction::Going => "Hasta la vista!",
    };
    h1![
	class! {"heading"},
	style! ["height" => "100vh",
		"width" => "100vw",],
	{ greeting },
	// simple_ev(Ev::Click, Msg::Click),
    ]
}

fn init(_url: Url, orders: &mut impl Orders<Msg>) -> Model {
    // orders provides a mechanism for us to be able to add messages or futures to a queue
    orders.perform_cmd(fetch_drills());
    Model {
	direction: Direction::Coming,
    }
}

// this sets things up so that it is called as soon as the module is loaded
#[wasm_bindgen(start)]
pub fn render() {
    seed::App::build(init, update, view).finish().run();
}
#+END_SRC

#+name:
#+BEGIN_SRC rust :tangle irwa/src/lib.rs
#[macro_use]
extern crate serde;

#[derive(Clone, Debug, Deserialize, Serialize)]
pub struct Task {
    pub id: i32,
    pub title: String,
}

#[derive(Clone, Debug, Deserialize, Serialize)]
pub struct JsonApiResponse {
    pub data: Vec<Task>,
}
#+END_SRC

** A Side Note on Refactoring and Testing

   

